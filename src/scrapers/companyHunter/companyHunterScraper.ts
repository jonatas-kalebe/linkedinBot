import { Page } from 'puppeteer';
import { Scraper } from '../scraper.interface';
import { JobData } from '../../core/jobProcessor';
import { companyDB, CompanyEntry } from './database';
import { fetchYCombinatorCompanies } from './discovery/ycombinator/fetcher';
import { fetchRemoteOkCompanies } from './discovery/remoteok/fetcher';
import { gatherIntelligence } from './intelligence/gatherer';
import { extractJobDataWithAI } from './intelligence/aiExtractor';
import { humanizedWait } from '../../utils/humanization';
import { fetchA16ZCompanies } from './discovery/a16z/fetcher';
import { findJobLinksWithAI } from "../../services/aiLinkFinder"; // Verifique o caminho deste import

let discoveryHasRunInThisCycle = false;
let jobLinksToProcess: { company: CompanyEntry; url: string }[] = [];

export const companyHunterScraper: Scraper = {
  name: 'CompanyHunter',
  run: async function* (page: Page): AsyncGenerator<JobData> {
    // <<< MUDANÃ‡A-CHAVE: Loop de trabalho contÃ­nuo >>>
    // O bot agora busca ativamente a prÃ³xima tarefa sem precisar ser chamado novamente.
    while (true) {
      // --- ETAPA 1 (PRIORIDADE MÃXIMA): Processar links de vagas jÃ¡ encontrados ---
      if (jobLinksToProcess.length > 0) {
        const jobToProcess = jobLinksToProcess.shift()!;
        console.log(`[PROCESSANDO VAGA] ${jobToProcess.url.substring(0, 100)}...`);
        try {
          const jobDetails = await extractJobDataWithAI(page, jobToProcess.url);
          if (jobDetails && jobDetails.title && jobDetails.description) {
            yield { // <<< YIELD: Envia o dado da vaga para fora
              url: jobToProcess.url,
              title: jobDetails.title,
              company: jobDetails.company || jobToProcess.company.name,
              description: jobDetails.description,
              source: `${this.name} (${jobToProcess.company.name})`
            };
          }
        } catch (error: any) {
            console.error(`[ERRO NA EXTRAÃ‡ÃƒO IA] Falha ao processar ${jobToProcess.url}. Causa: ${error.message}`);
        }
        continue; // <<< CONTINUE: Volta ao inÃ­cio do loop para processar o prÃ³ximo link da fila
      }

      // --- ETAPA 2: Encontrar vagas em empresas com inteligÃªncia coletada ---
      const companyToScrape = companyDB.getNextCompanyForJobScraping();
      if (companyToScrape && companyToScrape.careersUrl) {
        console.log(`[BUSCANDO VAGAS] Na empresa: ${companyToScrape.name} (${companyToScrape.careersUrl})`);
        try {
          await page.goto(companyToScrape.careersUrl, { waitUntil: 'networkidle2', timeout: 60000 }); // Timeout reduzido para agilidade
          const jobLinks = await findJobLinksWithAI(page, companyToScrape.careersUrl);

          if (jobLinks.length > 0) {
            console.log(`[VAGAS ENCONTRADAS] ${jobLinks.length} vagas em ${companyToScrape.name}. Adicionando Ã  fila.`);
            jobLinksToProcess.push(...jobLinks.map(url => ({ company: companyToScrape, url })));
          } else {
            console.log(`[SEM VAGAS] Nenhuma vaga encontrada via IA em ${companyToScrape.name}.`);
          }
          await companyDB.updateCompany(companyToScrape.domain, { status: 'jobs_scraped' });
        } catch (e: any) {
          console.error(`[ERRO AO BUSCAR VAGAS] Falha ao processar ${companyToScrape.careersUrl}. Causa: ${e.message}`);
          await companyDB.updateCompany(companyToScrape.domain, { status: 'failed' });
        }
        await humanizedWait(page, 1000, 2000); // Espera reduzida
        continue; // <<< CONTINUE: Volta ao inÃ­cio para jÃ¡ processar os links que acabou de encontrar
      }

      // --- ETAPA 3: Coletar inteligÃªncia (URL de carreiras, etc.) ---
      const companyToIntelligence = companyDB.getNextCompanyForIntelligence();
      if (companyToIntelligence) {
        console.log(`[COLETANDO INTELIGÃŠNCIA] Para a empresa: ${companyToIntelligence.name}`);
        try {
            const intelligenceData = await gatherIntelligence(page, companyToIntelligence);
            const newStatus = intelligenceData.careersUrl ? 'intelligence_gathered' : 'jobs_scraped'; // Se nÃ£o achar URL, pula direto
            console.log(`[INTELIGÃŠNCIA OK] Status de ${companyToIntelligence.name} -> ${newStatus}`);
            await companyDB.updateCompany(companyToIntelligence.domain, { ...intelligenceData, status: newStatus });
        } catch (e: any) {
            console.error(`[ERRO NA INTELIGÃŠNCIA] Falha ao coletar dados de ${companyToIntelligence.name}. Causa: ${e.message}`);
            await companyDB.updateCompany(companyToIntelligence.domain, { status: 'failed' });
        }
        await humanizedWait(page, 1000, 2000);
        continue; // <<< CONTINUE: Volta ao inÃ­cio para a prÃ³xima tarefa
      }

      // --- ETAPA 4: Descobrir novas empresas (se nÃ£o houver mais nada pra fazer) ---
      if (!discoveryHasRunInThisCycle) {
        console.log(`[DESCOBERTA] Fim do ciclo de scraping. Buscando novas empresas...`);
        discoveryHasRunInThisCycle = true;
        const browser = page.browser();
        
        // Seu cÃ³digo de descoberta estÃ¡ Ã³timo e pode permanecer o mesmo.
        const [ycCompanies, a16zCompanies, remoteOkCompanies] = await Promise.all([
        (async () => {
          const p = await browser.newPage()
          try {
            return await fetchYCombinatorCompanies(p)
          } finally {
            await p.close()
          }
        })(),
        (async () => {
          const p = await browser.newPage()
          try {
            return await fetchA16ZCompanies(p)
          } finally {
            await p.close()
          }
        })(),
        (async () => {
          const p = await browser.newPage()
          try {
            return await fetchRemoteOkCompanies(p)
          } finally {
            await p.close()
          }
        })()
      ])
        
        await companyDB.addDiscoveredCompanies(ycCompanies.map(c => ({...c, source: 'YCombinator'})));
        await companyDB.addDiscoveredCompanies(a16zCompanies.map(c => ({...c, source: 'A16Z'})));
        await companyDB.addDiscoveredCompanies(remoteOkCompanies.map(c => ({...c, source: 'RemoteOK'})));
        
        console.log(`[DESCOBERTA FINALIZADA] Reiniciando ciclo de trabalho.`);
        ; // <<< CONTINUE: Volta ao inÃ­cio para comeÃ§ar a coletar inteligÃªncia das novas empresas.
      }

      // --- ETAPA 5 (CONDIÃ‡ÃƒO DE SAÃDA): Fim de tudo ---
      // Se chegou atÃ© aqui, significa que todos os `if` anteriores falharam.
      // NÃ£o hÃ¡ mais links para processar, nem empresas para analisar, e a descoberta jÃ¡ rodou.
      console.log("ðŸ Todos os ciclos foram concluÃ­dos. Nenhuma nova aÃ§Ã£o a ser tomada.");
      break; // <<< BREAK: Sai do loop while(true) e encerra o gerador.
    }
  }
};

export function resetCompanyHunterCycle() {
  console.log("â™»ï¸ Ciclo do CompanyHunter reiniciado.");
  discoveryHasRunInThisCycle = false;
  jobLinksToProcess = [];
  companyDB.resetScrapingStatus(); // Agora podemos usar a funÃ§Ã£o de reset do DB
}
